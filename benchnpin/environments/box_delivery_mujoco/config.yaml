render:
  show: true
  show_obs: true

boxes:
  num_boxes: 10
  clearance: 0.2
  box_half_size: 0.04

train:
  train_mode: false
  job_type: 'sam'
  job_name: 'sam_model'
  batch_size: 32
  checkpoint_freq: 6000
  exploration_timesteps: 6000
  final_exploration: 0.01
  gamma: 0.99
  grad_norm_clipping: 10
  job_id_to_resume: null
  learning_rate: 0.01
  learning_starts: 1000
  n_epochs: 10
  n_steps: 256
  replay_buffer_size: 10000
  resume_training: false
  target_update_freq: 1000
  total_timesteps: 60000
  use_correct_direction_reward: true
  verbose: 2
  weight_decay: 0.0001
  tries_before_inactive: 3000

  
### ENVIRONMENT PARAMS
env:
  obstacle_config: small_columns # options are small_empty, small_columns, large_columns, large_divider
  room_length: 2.845
  room_width_small: 1.4225
  room_width_large: 2.5
  shortest_path_channel_scale: 0.25
  local_map_pixel_width: 224
  local_map_pixel_width_sam: 96
  wall_thickness: 24.0 # Really high wall thickness to ensure nothing in vicinity of local maps
  invert_receptacle_map: false
  receptacle_position: [-0.56125, 1.2725]
  receptacle_half: 0.15
  sim_timestep: 0.01 

small_pillars:
  num_pillars: 2
  adjust_num_pillars: True # if true, number of pillars would be randomized after each reset to be between 1 and num_pillars
  pillar_half: [0.14225, 0.14225, 0.20]

large_pillars:
  num_pillars: 8
  adjust_num_pillars: True
  # pillar_half: [0.16, 0.16, 0.10]
  pillar_half: [0.14225, 0.14225, 0.20]

# NOT WORKING YET
large_divider:
  divider_half: 0
  divider_height: 0

misc:
  ministep_size: 2.5
  inactivity_cutoff_sam: 100
  inactivity_cutoff: 200
  random_seed: 42

agent:
  action_type: 'position' # options are velocity, heading, position
  length: 0.138
  width: 0.183
  robot_clear: 0.15

rewards_sam:
  partial_rewards_scale: 0.2
  goal_reward: 1.0
  collision_penalty: 0.25
  non_movement_penalty: 0.25
  correct_direction_reward_scale: 1
